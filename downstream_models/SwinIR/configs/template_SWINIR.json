{
  "task": "swin_ship_8x", //  classical image sr for x2/x3/x4/x8. root/task/images-models-options
  "model": "plain", // "plain" | "plain2" if two inputs
  "gpu_ids": [0, 1],
  "dist": true,


  "scale": 8, // 2 | 3 | 4 | 8
  "n_channels": 3, // broadcast to "datasets", 1 for grayscale, 3 for color
  

  "path": {
    "root": "superresolution",
    "pretrained_netG": null, // path of pretrained model. We fine-tune X3/X4/X8 models from X2 model, so that `G_optimizer_lr` and `G_scheduler_milestones` can be halved to save time.
    "pretrained_netE": null // path of pretrained model
  },


  "datasets": {
    
    "train": {
      "name": "train_dataset_swinir",
      "dataset_type": "sr",
      "dataroot_H": "", // path of H training dataset
      "dataroot_L": "", // path of L training dataset
      "H_size": 512, // 96/144|192/384 | 128/192/256/512. LR patch size is set to 48 or 64 when compared with RCAN or RRDB.
      "dataloader_shuffle": true,
      "dataloader_num_workers": 16,
      "dataloader_batch_size": //era 32
    },

    "test": {
      "name": "test_dataset_swinir", // just name
      "dataset_type": "sr",
      "dataroot_H": "", // path of H testing dataset
      "dataroot_L": "" // path of L testing dataset
    }
  },


  "netG": {
    "net_type": "swinir",
    "upscale": 8, // 2 | 3  | 4 | 8
    "in_chans": 3,
    "img_size": 64, // For fair comparison, LR patch size is set to 48 or 64 when compared with RCAN or RRDB.
    "window_size": 8,
    "img_range": 1.0,
    "depths": [
      6,
      6,
      6,
      6,
      6,
      6
    ],
    "embed_dim": 180,
    "num_heads": [
      6,
      6,
      6,
      6,
      6,
      6
    ],
    "mlp_ratio": 2,
    "upsampler": "pixelshuffle", // "pixelshuffle" | "pixelshuffledirect" | "nearest+conv" | null
    "resi_connection": "1conv", // "1conv" | "3conv"
    "init_type": "default"
  },


  "train": {
    "G_lossfn_type": "l1", // "l1" preferred | "l2sum" | "l2" | "ssim" | "charbonnier"
    "G_lossfn_weight": 1.0, // default
    "E_decay": 0.999, // Exponential Moving Average for netG: set 0 to disable; default setting 0.999
    
    "G_optimizer_type": "adam",
    "G_optimizer_lr": 2e-4,
    "G_optimizer_wd": 0, // weight decay, default 0
    "G_optimizer_clipgrad": null, // unused
    "G_optimizer_reuse": true, 
    
    "G_scheduler_type": "MultiStepLR", // "MultiStepLR" is enough
    "G_scheduler_milestones": [
      250000,
      400000,
      450000,
      475000,
      500000
    ],
    "G_scheduler_gamma": 0.5,
    
    "G_regularizer_orthstep": null, // unused
    "G_regularizer_clipstep": null, // unused
    
    "G_param_strict": true,
    "E_param_strict": true,
    
    "checkpoint_test": 5000, // for testing
    "checkpoint_save": 5000, // for saving model
    "checkpoint_print": 1 // for print
  }
}